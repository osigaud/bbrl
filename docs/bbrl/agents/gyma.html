<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>bbrl.agents.gyma API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>bbrl.agents.gyma</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python"># This source code is licensed under the MIT license found in the
# LICENSE file in the root directory of this source tree.
#

import numpy as np
import torch

import gym
from bbrl.agents.agent import Agent


def _convert_action(action):
    if len(action.size()) == 0:
        action = action.item()
        assert isinstance(action, int)
    else:
        action = np.array(action.tolist())
    return action


def _format_frame(frame):
    if isinstance(frame, dict):
        r = {}
        for k in frame:
            r[k] = _format_frame(frame[k])
        return r
    elif isinstance(frame, list):
        t = torch.tensor(frame).unsqueeze(0)
        if t.dtype == torch.float64 or t.dtype == torch.float32:
            t = t.float()
        else:
            t = t.long()
        return t
    elif isinstance(frame, np.ndarray):
        t = torch.from_numpy(frame).unsqueeze(0)
        if t.dtype == torch.float64 or t.dtype == torch.float32:
            t = t.float()
        else:
            t = t.long()
        return t
    elif isinstance(frame, torch.Tensor):
        return frame.unsqueeze(0)  # .float()
    elif isinstance(frame, bool):
        return torch.tensor([frame]).bool()
    elif isinstance(frame, int):
        return torch.tensor([frame]).long()
    elif isinstance(frame, float):
        return torch.tensor([frame]).float()

    else:
        try:
            # Check if it is a LazyFrame from OpenAI Baselines
            o = torch.from_numpy(frame.__array__()).unsqueeze(0).float()
            return o
        except TypeError:
            assert False


def _torch_type(d):
    nd = {}
    for k in d:
        if d[k].dtype == torch.float64:
            nd[k] = d[k].float()
        else:
            nd[k] = d[k]
    return nd


def _torch_cat_dict(d):
    r = {}
    for k in d[0]:
        r[k] = torch.cat([dd[k] for dd in d], dim=0)
    return r


class GymAgent(Agent):
    &#34;&#34;&#34;Create an Agent from a gym environment&#34;&#34;&#34;

    def __init__(
        self,
        make_env_fn=None,
        make_env_args={},
        n_envs=None,
        seed=None,
        action_string=&#34;action&#34;,
        output=&#34;env/&#34;,
    ):
        &#34;&#34;&#34;Create an agent from a Gym environment

        Args:
            make_env_fn ([function that returns a gym.Env]): The function to create a single gym environments
            make_env_args (dict): The arguments of the function that creates a gym.Env
            n_envs ([int]): The number of environments to create.
            action_string (str, optional): [the name of the action variable in the workspace]. Defaults to &#34;action&#34;.
            output (str, optional): [the output prefix of the environment]. Defaults to &#34;env/&#34;.
            seed (int): the seed used to initialize the environment
            and each environment will have its own seed]. Defaults to True.
        &#34;&#34;&#34;
        super().__init__()
        assert n_envs &gt; 0
        self.envs = None
        self.env_args = make_env_args
        self._seed = seed
        assert self._seed is not None, &#34;[GymAgent] seeds must be specified&#34;

        self.n_envs = n_envs
        self.output = output
        self.input = action_string
        self.make_env_fn = make_env_fn
        self.ghost_params = torch.nn.Parameter(torch.randn(()))
        self.timestep = torch.tensor([0 for _ in range(n_envs)])
        self.finished = torch.tensor([True for _ in range(n_envs)])
        self.truncated = torch.tensor([False for _ in range(n_envs)])

        self.envs = [self.make_env_fn(**self.env_args) for _ in range(self.n_envs)]
        for k in range(self.n_envs):
            self.envs[k].seed(self._seed + k)

        self.observation_space = self.envs[0].observation_space
        self.action_space = self.envs[0].action_space
        self.finished = torch.tensor([True for _ in self.envs])
        self.truncated = torch.tensor([True for _ in self.envs])
        self.timestep = torch.tensor([0 for _ in self.envs])
        self.cumulated_reward = {}
        self.last_frame = {}

    def _common_reset(self, k, save_render):
        env = self.envs[k]
        self.cumulated_reward[k] = 0.0
        o = env.reset()
        observation = _format_frame(o)

        if isinstance(observation, torch.Tensor):
            observation = {&#34;env_obs&#34;: observation}
        else:
            assert isinstance(observation, dict)
        if save_render:
            image = env.render(mode=&#34;image&#34;).unsqueeze(0)
            observation[&#34;rendering&#34;] = image

        self.finished[k] = False
        self.truncated[k] = False
        self.timestep[k] = 0

        ret = {
            **observation,
            &#34;done&#34;: torch.tensor([False]),
            &#34;truncated&#34;: torch.tensor([False]),
            &#34;reward&#34;: torch.tensor([0.0]).float(),
            &#34;timestep&#34;: torch.tensor([self.timestep[k]]),
            &#34;cumulated_reward&#34;: torch.tensor([self.cumulated_reward[k]]).float(),
        }
        return _torch_type(ret), observation

    def _reset(self, k, save_render):
        ret, observation = self._common_reset(k, save_render)
        self.last_frame[k] = observation
        return ret

    def _make_step(self, env, action, k, save_render):
        action = _convert_action(action)

        obs, reward, done, info = env.step(action)
        if &#34;TimeLimit.truncated&#34; in info.keys():
            truncated = info[&#34;TimeLimit.truncated&#34;]
        else:
            truncated = False
        self.cumulated_reward[k] += reward
        observation = _format_frame(obs)
        if isinstance(observation, torch.Tensor):
            observation = {&#34;env_obs&#34;: observation}
        else:
            assert isinstance(observation, dict)
        if save_render:
            image = env.render(mode=&#34;image&#34;).unsqueeze(0)
            observation[&#34;rendering&#34;] = image
        ret = {
            **observation,
            &#34;done&#34;: torch.tensor([done]),
            &#34;truncated&#34;: torch.tensor([truncated]),
            &#34;reward&#34;: torch.tensor([reward]).float(),
            &#34;cumulated_reward&#34;: torch.tensor([self.cumulated_reward[k]]),
            &#34;timestep&#34;: torch.tensor([self.timestep[k]]),
        }
        return _torch_type(ret), done, truncated, observation

    def _step(self, k, action, save_render):
        if self.finished[k]:
            assert k in self.last_frame
            return {
                **self.last_frame[k],
                &#34;done&#34;: torch.tensor([True]),
                &#34;truncated&#34;: torch.tensor([self.truncated[k]]),
                &#34;reward&#34;: torch.tensor([0.0]).float(),
                &#34;cumulated_reward&#34;: torch.tensor([self.cumulated_reward[k]]).float(),
                &#34;timestep&#34;: torch.tensor([self.timestep[k]]),
            }
        self.timestep[k] += 1
        ret, done, truncated, observation = self._make_step(
            self.envs[k], action, k, save_render
        )

        self.last_frame[k] = observation
        if done:
            self.finished[k] = True
            self.truncated[k] = truncated
        return ret

    def set_obs(self, observations, t):
        observations = _torch_cat_dict(observations)
        for k in observations:
            self.set((self.output + k, t), observations[k].to(self.ghost_params.device))

    def forward(self, t=0, save_render=False, **kwargs):
        &#34;&#34;&#34;Do one step by reading the `action` at t-1
        If t==0, environments are reset
        If save_render is True, then the output of env.render(mode=&#34;image&#34;) is written as env/rendering
        &#34;&#34;&#34;

        if t == 0:
            self.timestep = torch.tensor([0 for _ in self.envs])
            observations = []
            for k, e in enumerate(self.envs):
                obs = self._reset(k, save_render)
                observations.append(obs)
            observations = _torch_cat_dict(observations)
            for k in observations:
                self.set(
                    (self.output + k, t), observations[k].to(self.ghost_params.device)
                )
        else:
            assert t &gt; 0
            action = self.get((self.input, t - 1))
            assert action.size()[0] == self.n_envs, &#34;Incompatible number of envs&#34;
            observations = []
            for k, e in enumerate(self.envs):
                obs = self._step(k, action[k], save_render)
                observations.append(obs)
            self.set_obs(observations, t)

    def is_continuous_action(self):
        return isinstance(self.action_space, gym.spaces.Box)

    def is_discrete_action(self):
        return isinstance(self.action_space, gym.spaces.Discrete)

    def is_continuous_state(self):
        return isinstance(self.observation_space, gym.spaces.Box)

    def is_discrete_state(self):
        return isinstance(self.observation_space, gym.spaces.Discrete)

    def get_obs_and_actions_sizes(self):
        action_dim = 0
        state_dim = 0
        if self.is_continuous_action():
            action_dim = self.action_space.shape[0]
        elif self.is_discrete_action():
            action_dim = self.action_space.n
        if self.is_continuous_state():
            state_dim = self.observation_space.shape[0]
        elif self.is_discrete_state():
            state_dim = self.observation_space.n
        return state_dim, action_dim


class AutoResetGymAgent(GymAgent):
    &#34;&#34;&#34;The same as GymAgent, but with an automatic reset when done is True&#34;&#34;&#34;

    def __init__(
        self,
        make_env_fn=None,
        make_env_args={},
        n_envs=None,
        seed=None,
        action_string=&#34;action&#34;,
        output=&#34;env/&#34;,
    ):
        &#34;&#34;&#34;Create an agent from a Gym environment with Autoreset

        Args:
            make_env_fn ([function that returns a gym.Env]): The function to create a single gym environments
            make_env_args (dict): The arguments of the function that creates a gym.Env
            n_envs ([int]): The number of environments to create.
            action_string (str, optional): [the name of the action variable in the workspace]. Defaults to &#34;action&#34;.
            output (str, optional): [the output prefix of the environment]. Defaults to &#34;env/&#34;.
            seed (int): the seed used to initialize the environment
            and each environment will have its own seed]. Defaults to True.
        &#34;&#34;&#34;
        super().__init__(
            make_env_fn=make_env_fn,
            make_env_args=make_env_args,
            n_envs=n_envs,
            seed=seed,
            action_string=action_string,
            output=output,
        )
        self.is_running = [False for _ in range(self.n_envs)]

    def _reset(self, k, save_render):
        self.is_running[k] = True
        ret, _ = self._common_reset(k, save_render)
        return ret

    def _step(self, k, action, save_render):
        self.timestep[k] += 1
        ret, done, truncated, _ = self._make_step(self.envs[k], action, k, save_render)
        if done:
            self.is_running[k] = False
            self.truncated[k] = truncated
        return ret

    def forward(self, t=0, save_render=False, **kwargs):
        &#34;&#34;&#34;
        Perform one step by reading the `action`
        &#34;&#34;&#34;

        observations = []
        for k, env in enumerate(self.envs):
            if not self.is_running[k] or t == 0:
                observations.append(self._reset(k, save_render))
            else:
                assert t &gt; 0
                action = self.get((self.input, t - 1))
                assert action.size()[0] == self.n_envs, &#34;Incompatible number of envs&#34;
                observations.append(self._step(k, action[k], save_render))

        self.set_obs(observations, t)


class NoAutoResetGymAgent(GymAgent):
    &#34;&#34;&#34;The same as GymAgent, named to make sure it is not AutoReset&#34;&#34;&#34;

    def __init__(
        self,
        make_env_fn=None,
        make_env_args={},
        n_envs=None,
        seed=None,
        action_string=&#34;action&#34;,
        output=&#34;env/&#34;,
    ):
        super().__init__(
            make_env_fn=make_env_fn,
            make_env_args=make_env_args,
            n_envs=n_envs,
            seed=seed,
            action_string=action_string,
            output=output,
        )</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="bbrl.agents.gyma.AutoResetGymAgent"><code class="flex name class">
<span>class <span class="ident">AutoResetGymAgent</span></span>
<span>(</span><span>make_env_fn=None, make_env_args={}, n_envs=None, seed=None, action_string='action', output='env/')</span>
</code></dt>
<dd>
<div class="desc"><p>The same as GymAgent, but with an automatic reset when done is True</p>
<p>Create an agent from a Gym environment with Autoreset</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>make_env_fn</code></strong> :&ensp;<code>[function that returns a gym.Env]</code></dt>
<dd>The function to create a single gym environments</dd>
<dt><strong><code>make_env_args</code></strong> :&ensp;<code>dict</code></dt>
<dd>The arguments of the function that creates a gym.Env</dd>
<dt><strong><code>n_envs</code></strong> :&ensp;<code>[int]</code></dt>
<dd>The number of environments to create.</dd>
<dt><strong><code>action_string</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>[the name of the action variable in the workspace]. Defaults to "action".</dd>
<dt><strong><code>output</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>[the output prefix of the environment]. Defaults to "env/".</dd>
<dt><strong><code>seed</code></strong> :&ensp;<code>int</code></dt>
<dd>the seed used to initialize the environment</dd>
</dl>
<p>and each environment will have its own seed]. Defaults to True.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class AutoResetGymAgent(GymAgent):
    &#34;&#34;&#34;The same as GymAgent, but with an automatic reset when done is True&#34;&#34;&#34;

    def __init__(
        self,
        make_env_fn=None,
        make_env_args={},
        n_envs=None,
        seed=None,
        action_string=&#34;action&#34;,
        output=&#34;env/&#34;,
    ):
        &#34;&#34;&#34;Create an agent from a Gym environment with Autoreset

        Args:
            make_env_fn ([function that returns a gym.Env]): The function to create a single gym environments
            make_env_args (dict): The arguments of the function that creates a gym.Env
            n_envs ([int]): The number of environments to create.
            action_string (str, optional): [the name of the action variable in the workspace]. Defaults to &#34;action&#34;.
            output (str, optional): [the output prefix of the environment]. Defaults to &#34;env/&#34;.
            seed (int): the seed used to initialize the environment
            and each environment will have its own seed]. Defaults to True.
        &#34;&#34;&#34;
        super().__init__(
            make_env_fn=make_env_fn,
            make_env_args=make_env_args,
            n_envs=n_envs,
            seed=seed,
            action_string=action_string,
            output=output,
        )
        self.is_running = [False for _ in range(self.n_envs)]

    def _reset(self, k, save_render):
        self.is_running[k] = True
        ret, _ = self._common_reset(k, save_render)
        return ret

    def _step(self, k, action, save_render):
        self.timestep[k] += 1
        ret, done, truncated, _ = self._make_step(self.envs[k], action, k, save_render)
        if done:
            self.is_running[k] = False
            self.truncated[k] = truncated
        return ret

    def forward(self, t=0, save_render=False, **kwargs):
        &#34;&#34;&#34;
        Perform one step by reading the `action`
        &#34;&#34;&#34;

        observations = []
        for k, env in enumerate(self.envs):
            if not self.is_running[k] or t == 0:
                observations.append(self._reset(k, save_render))
            else:
                assert t &gt; 0
                action = self.get((self.input, t - 1))
                assert action.size()[0] == self.n_envs, &#34;Incompatible number of envs&#34;
                observations.append(self._step(k, action[k], save_render))

        self.set_obs(observations, t)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="bbrl.agents.gyma.GymAgent" href="#bbrl.agents.gyma.GymAgent">GymAgent</a></li>
<li><a title="bbrl.agents.agent.Agent" href="agent.html#bbrl.agents.agent.Agent">Agent</a></li>
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="bbrl.agents.gyma.AutoResetGymAgent.dump_patches"><code class="name">var <span class="ident">dump_patches</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="bbrl.agents.gyma.AutoResetGymAgent.training"><code class="name">var <span class="ident">training</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="bbrl.agents.gyma.AutoResetGymAgent.forward"><code class="name flex">
<span>def <span class="ident">forward</span></span>(<span>self, t=0, save_render=False, **kwargs) ‑> Callable[..., Any]</span>
</code></dt>
<dd>
<div class="desc"><p>Perform one step by reading the <code>action</code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def forward(self, t=0, save_render=False, **kwargs):
    &#34;&#34;&#34;
    Perform one step by reading the `action`
    &#34;&#34;&#34;

    observations = []
    for k, env in enumerate(self.envs):
        if not self.is_running[k] or t == 0:
            observations.append(self._reset(k, save_render))
        else:
            assert t &gt; 0
            action = self.get((self.input, t - 1))
            assert action.size()[0] == self.n_envs, &#34;Incompatible number of envs&#34;
            observations.append(self._step(k, action[k], save_render))

    self.set_obs(observations, t)</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="bbrl.agents.gyma.GymAgent" href="#bbrl.agents.gyma.GymAgent">GymAgent</a></b></code>:
<ul class="hlist">
<li><code><a title="bbrl.agents.gyma.GymAgent.clone" href="agent.html#bbrl.agents.agent.Agent.clone">clone</a></code></li>
<li><code><a title="bbrl.agents.gyma.GymAgent.get" href="agent.html#bbrl.agents.agent.Agent.get">get</a></code></li>
<li><code><a title="bbrl.agents.gyma.GymAgent.get_by_name" href="agent.html#bbrl.agents.agent.Agent.get_by_name">get_by_name</a></code></li>
<li><code><a title="bbrl.agents.gyma.GymAgent.get_name" href="agent.html#bbrl.agents.agent.Agent.get_name">get_name</a></code></li>
<li><code><a title="bbrl.agents.gyma.GymAgent.get_time_truncated" href="agent.html#bbrl.agents.agent.Agent.get_time_truncated">get_time_truncated</a></code></li>
<li><code><a title="bbrl.agents.gyma.GymAgent.is_running" href="agent.html#bbrl.agents.agent.Agent.is_running">is_running</a></code></li>
<li><code><a title="bbrl.agents.gyma.GymAgent.load_model" href="agent.html#bbrl.agents.agent.Agent.load_model">load_model</a></code></li>
<li><code><a title="bbrl.agents.gyma.GymAgent.save_model" href="agent.html#bbrl.agents.agent.Agent.save_model">save_model</a></code></li>
<li><code><a title="bbrl.agents.gyma.GymAgent.seed" href="agent.html#bbrl.agents.agent.Agent.seed">seed</a></code></li>
<li><code><a title="bbrl.agents.gyma.GymAgent.set" href="agent.html#bbrl.agents.agent.Agent.set">set</a></code></li>
<li><code><a title="bbrl.agents.gyma.GymAgent.set_name" href="agent.html#bbrl.agents.agent.Agent.set_name">set_name</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="bbrl.agents.gyma.GymAgent"><code class="flex name class">
<span>class <span class="ident">GymAgent</span></span>
<span>(</span><span>make_env_fn=None, make_env_args={}, n_envs=None, seed=None, action_string='action', output='env/')</span>
</code></dt>
<dd>
<div class="desc"><p>Create an Agent from a gym environment</p>
<p>Create an agent from a Gym environment</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>make_env_fn</code></strong> :&ensp;<code>[function that returns a gym.Env]</code></dt>
<dd>The function to create a single gym environments</dd>
<dt><strong><code>make_env_args</code></strong> :&ensp;<code>dict</code></dt>
<dd>The arguments of the function that creates a gym.Env</dd>
<dt><strong><code>n_envs</code></strong> :&ensp;<code>[int]</code></dt>
<dd>The number of environments to create.</dd>
<dt><strong><code>action_string</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>[the name of the action variable in the workspace]. Defaults to "action".</dd>
<dt><strong><code>output</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>[the output prefix of the environment]. Defaults to "env/".</dd>
<dt><strong><code>seed</code></strong> :&ensp;<code>int</code></dt>
<dd>the seed used to initialize the environment</dd>
</dl>
<p>and each environment will have its own seed]. Defaults to True.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class GymAgent(Agent):
    &#34;&#34;&#34;Create an Agent from a gym environment&#34;&#34;&#34;

    def __init__(
        self,
        make_env_fn=None,
        make_env_args={},
        n_envs=None,
        seed=None,
        action_string=&#34;action&#34;,
        output=&#34;env/&#34;,
    ):
        &#34;&#34;&#34;Create an agent from a Gym environment

        Args:
            make_env_fn ([function that returns a gym.Env]): The function to create a single gym environments
            make_env_args (dict): The arguments of the function that creates a gym.Env
            n_envs ([int]): The number of environments to create.
            action_string (str, optional): [the name of the action variable in the workspace]. Defaults to &#34;action&#34;.
            output (str, optional): [the output prefix of the environment]. Defaults to &#34;env/&#34;.
            seed (int): the seed used to initialize the environment
            and each environment will have its own seed]. Defaults to True.
        &#34;&#34;&#34;
        super().__init__()
        assert n_envs &gt; 0
        self.envs = None
        self.env_args = make_env_args
        self._seed = seed
        assert self._seed is not None, &#34;[GymAgent] seeds must be specified&#34;

        self.n_envs = n_envs
        self.output = output
        self.input = action_string
        self.make_env_fn = make_env_fn
        self.ghost_params = torch.nn.Parameter(torch.randn(()))
        self.timestep = torch.tensor([0 for _ in range(n_envs)])
        self.finished = torch.tensor([True for _ in range(n_envs)])
        self.truncated = torch.tensor([False for _ in range(n_envs)])

        self.envs = [self.make_env_fn(**self.env_args) for _ in range(self.n_envs)]
        for k in range(self.n_envs):
            self.envs[k].seed(self._seed + k)

        self.observation_space = self.envs[0].observation_space
        self.action_space = self.envs[0].action_space
        self.finished = torch.tensor([True for _ in self.envs])
        self.truncated = torch.tensor([True for _ in self.envs])
        self.timestep = torch.tensor([0 for _ in self.envs])
        self.cumulated_reward = {}
        self.last_frame = {}

    def _common_reset(self, k, save_render):
        env = self.envs[k]
        self.cumulated_reward[k] = 0.0
        o = env.reset()
        observation = _format_frame(o)

        if isinstance(observation, torch.Tensor):
            observation = {&#34;env_obs&#34;: observation}
        else:
            assert isinstance(observation, dict)
        if save_render:
            image = env.render(mode=&#34;image&#34;).unsqueeze(0)
            observation[&#34;rendering&#34;] = image

        self.finished[k] = False
        self.truncated[k] = False
        self.timestep[k] = 0

        ret = {
            **observation,
            &#34;done&#34;: torch.tensor([False]),
            &#34;truncated&#34;: torch.tensor([False]),
            &#34;reward&#34;: torch.tensor([0.0]).float(),
            &#34;timestep&#34;: torch.tensor([self.timestep[k]]),
            &#34;cumulated_reward&#34;: torch.tensor([self.cumulated_reward[k]]).float(),
        }
        return _torch_type(ret), observation

    def _reset(self, k, save_render):
        ret, observation = self._common_reset(k, save_render)
        self.last_frame[k] = observation
        return ret

    def _make_step(self, env, action, k, save_render):
        action = _convert_action(action)

        obs, reward, done, info = env.step(action)
        if &#34;TimeLimit.truncated&#34; in info.keys():
            truncated = info[&#34;TimeLimit.truncated&#34;]
        else:
            truncated = False
        self.cumulated_reward[k] += reward
        observation = _format_frame(obs)
        if isinstance(observation, torch.Tensor):
            observation = {&#34;env_obs&#34;: observation}
        else:
            assert isinstance(observation, dict)
        if save_render:
            image = env.render(mode=&#34;image&#34;).unsqueeze(0)
            observation[&#34;rendering&#34;] = image
        ret = {
            **observation,
            &#34;done&#34;: torch.tensor([done]),
            &#34;truncated&#34;: torch.tensor([truncated]),
            &#34;reward&#34;: torch.tensor([reward]).float(),
            &#34;cumulated_reward&#34;: torch.tensor([self.cumulated_reward[k]]),
            &#34;timestep&#34;: torch.tensor([self.timestep[k]]),
        }
        return _torch_type(ret), done, truncated, observation

    def _step(self, k, action, save_render):
        if self.finished[k]:
            assert k in self.last_frame
            return {
                **self.last_frame[k],
                &#34;done&#34;: torch.tensor([True]),
                &#34;truncated&#34;: torch.tensor([self.truncated[k]]),
                &#34;reward&#34;: torch.tensor([0.0]).float(),
                &#34;cumulated_reward&#34;: torch.tensor([self.cumulated_reward[k]]).float(),
                &#34;timestep&#34;: torch.tensor([self.timestep[k]]),
            }
        self.timestep[k] += 1
        ret, done, truncated, observation = self._make_step(
            self.envs[k], action, k, save_render
        )

        self.last_frame[k] = observation
        if done:
            self.finished[k] = True
            self.truncated[k] = truncated
        return ret

    def set_obs(self, observations, t):
        observations = _torch_cat_dict(observations)
        for k in observations:
            self.set((self.output + k, t), observations[k].to(self.ghost_params.device))

    def forward(self, t=0, save_render=False, **kwargs):
        &#34;&#34;&#34;Do one step by reading the `action` at t-1
        If t==0, environments are reset
        If save_render is True, then the output of env.render(mode=&#34;image&#34;) is written as env/rendering
        &#34;&#34;&#34;

        if t == 0:
            self.timestep = torch.tensor([0 for _ in self.envs])
            observations = []
            for k, e in enumerate(self.envs):
                obs = self._reset(k, save_render)
                observations.append(obs)
            observations = _torch_cat_dict(observations)
            for k in observations:
                self.set(
                    (self.output + k, t), observations[k].to(self.ghost_params.device)
                )
        else:
            assert t &gt; 0
            action = self.get((self.input, t - 1))
            assert action.size()[0] == self.n_envs, &#34;Incompatible number of envs&#34;
            observations = []
            for k, e in enumerate(self.envs):
                obs = self._step(k, action[k], save_render)
                observations.append(obs)
            self.set_obs(observations, t)

    def is_continuous_action(self):
        return isinstance(self.action_space, gym.spaces.Box)

    def is_discrete_action(self):
        return isinstance(self.action_space, gym.spaces.Discrete)

    def is_continuous_state(self):
        return isinstance(self.observation_space, gym.spaces.Box)

    def is_discrete_state(self):
        return isinstance(self.observation_space, gym.spaces.Discrete)

    def get_obs_and_actions_sizes(self):
        action_dim = 0
        state_dim = 0
        if self.is_continuous_action():
            action_dim = self.action_space.shape[0]
        elif self.is_discrete_action():
            action_dim = self.action_space.n
        if self.is_continuous_state():
            state_dim = self.observation_space.shape[0]
        elif self.is_discrete_state():
            state_dim = self.observation_space.n
        return state_dim, action_dim</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="bbrl.agents.agent.Agent" href="agent.html#bbrl.agents.agent.Agent">Agent</a></li>
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="bbrl.agents.gyma.AutoResetGymAgent" href="#bbrl.agents.gyma.AutoResetGymAgent">AutoResetGymAgent</a></li>
<li><a title="bbrl.agents.gyma.NoAutoResetGymAgent" href="#bbrl.agents.gyma.NoAutoResetGymAgent">NoAutoResetGymAgent</a></li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="bbrl.agents.gyma.GymAgent.dump_patches"><code class="name">var <span class="ident">dump_patches</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="bbrl.agents.gyma.GymAgent.training"><code class="name">var <span class="ident">training</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="bbrl.agents.gyma.GymAgent.forward"><code class="name flex">
<span>def <span class="ident">forward</span></span>(<span>self, t=0, save_render=False, **kwargs) ‑> Callable[..., Any]</span>
</code></dt>
<dd>
<div class="desc"><p>Do one step by reading the <code>action</code> at t-1
If t==0, environments are reset
If save_render is True, then the output of env.render(mode="image") is written as env/rendering</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def forward(self, t=0, save_render=False, **kwargs):
    &#34;&#34;&#34;Do one step by reading the `action` at t-1
    If t==0, environments are reset
    If save_render is True, then the output of env.render(mode=&#34;image&#34;) is written as env/rendering
    &#34;&#34;&#34;

    if t == 0:
        self.timestep = torch.tensor([0 for _ in self.envs])
        observations = []
        for k, e in enumerate(self.envs):
            obs = self._reset(k, save_render)
            observations.append(obs)
        observations = _torch_cat_dict(observations)
        for k in observations:
            self.set(
                (self.output + k, t), observations[k].to(self.ghost_params.device)
            )
    else:
        assert t &gt; 0
        action = self.get((self.input, t - 1))
        assert action.size()[0] == self.n_envs, &#34;Incompatible number of envs&#34;
        observations = []
        for k, e in enumerate(self.envs):
            obs = self._step(k, action[k], save_render)
            observations.append(obs)
        self.set_obs(observations, t)</code></pre>
</details>
</dd>
<dt id="bbrl.agents.gyma.GymAgent.get_obs_and_actions_sizes"><code class="name flex">
<span>def <span class="ident">get_obs_and_actions_sizes</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_obs_and_actions_sizes(self):
    action_dim = 0
    state_dim = 0
    if self.is_continuous_action():
        action_dim = self.action_space.shape[0]
    elif self.is_discrete_action():
        action_dim = self.action_space.n
    if self.is_continuous_state():
        state_dim = self.observation_space.shape[0]
    elif self.is_discrete_state():
        state_dim = self.observation_space.n
    return state_dim, action_dim</code></pre>
</details>
</dd>
<dt id="bbrl.agents.gyma.GymAgent.is_continuous_action"><code class="name flex">
<span>def <span class="ident">is_continuous_action</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def is_continuous_action(self):
    return isinstance(self.action_space, gym.spaces.Box)</code></pre>
</details>
</dd>
<dt id="bbrl.agents.gyma.GymAgent.is_continuous_state"><code class="name flex">
<span>def <span class="ident">is_continuous_state</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def is_continuous_state(self):
    return isinstance(self.observation_space, gym.spaces.Box)</code></pre>
</details>
</dd>
<dt id="bbrl.agents.gyma.GymAgent.is_discrete_action"><code class="name flex">
<span>def <span class="ident">is_discrete_action</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def is_discrete_action(self):
    return isinstance(self.action_space, gym.spaces.Discrete)</code></pre>
</details>
</dd>
<dt id="bbrl.agents.gyma.GymAgent.is_discrete_state"><code class="name flex">
<span>def <span class="ident">is_discrete_state</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def is_discrete_state(self):
    return isinstance(self.observation_space, gym.spaces.Discrete)</code></pre>
</details>
</dd>
<dt id="bbrl.agents.gyma.GymAgent.set_obs"><code class="name flex">
<span>def <span class="ident">set_obs</span></span>(<span>self, observations, t)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_obs(self, observations, t):
    observations = _torch_cat_dict(observations)
    for k in observations:
        self.set((self.output + k, t), observations[k].to(self.ghost_params.device))</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="bbrl.agents.agent.Agent" href="agent.html#bbrl.agents.agent.Agent">Agent</a></b></code>:
<ul class="hlist">
<li><code><a title="bbrl.agents.agent.Agent.clone" href="agent.html#bbrl.agents.agent.Agent.clone">clone</a></code></li>
<li><code><a title="bbrl.agents.agent.Agent.get" href="agent.html#bbrl.agents.agent.Agent.get">get</a></code></li>
<li><code><a title="bbrl.agents.agent.Agent.get_by_name" href="agent.html#bbrl.agents.agent.Agent.get_by_name">get_by_name</a></code></li>
<li><code><a title="bbrl.agents.agent.Agent.get_name" href="agent.html#bbrl.agents.agent.Agent.get_name">get_name</a></code></li>
<li><code><a title="bbrl.agents.agent.Agent.get_time_truncated" href="agent.html#bbrl.agents.agent.Agent.get_time_truncated">get_time_truncated</a></code></li>
<li><code><a title="bbrl.agents.agent.Agent.is_running" href="agent.html#bbrl.agents.agent.Agent.is_running">is_running</a></code></li>
<li><code><a title="bbrl.agents.agent.Agent.load_model" href="agent.html#bbrl.agents.agent.Agent.load_model">load_model</a></code></li>
<li><code><a title="bbrl.agents.agent.Agent.save_model" href="agent.html#bbrl.agents.agent.Agent.save_model">save_model</a></code></li>
<li><code><a title="bbrl.agents.agent.Agent.seed" href="agent.html#bbrl.agents.agent.Agent.seed">seed</a></code></li>
<li><code><a title="bbrl.agents.agent.Agent.set" href="agent.html#bbrl.agents.agent.Agent.set">set</a></code></li>
<li><code><a title="bbrl.agents.agent.Agent.set_name" href="agent.html#bbrl.agents.agent.Agent.set_name">set_name</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="bbrl.agents.gyma.NoAutoResetGymAgent"><code class="flex name class">
<span>class <span class="ident">NoAutoResetGymAgent</span></span>
<span>(</span><span>make_env_fn=None, make_env_args={}, n_envs=None, seed=None, action_string='action', output='env/')</span>
</code></dt>
<dd>
<div class="desc"><p>The same as GymAgent, named to make sure it is not AutoReset</p>
<p>Create an agent from a Gym environment</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>make_env_fn</code></strong> :&ensp;<code>[function that returns a gym.Env]</code></dt>
<dd>The function to create a single gym environments</dd>
<dt><strong><code>make_env_args</code></strong> :&ensp;<code>dict</code></dt>
<dd>The arguments of the function that creates a gym.Env</dd>
<dt><strong><code>n_envs</code></strong> :&ensp;<code>[int]</code></dt>
<dd>The number of environments to create.</dd>
<dt><strong><code>action_string</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>[the name of the action variable in the workspace]. Defaults to "action".</dd>
<dt><strong><code>output</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>[the output prefix of the environment]. Defaults to "env/".</dd>
<dt><strong><code>seed</code></strong> :&ensp;<code>int</code></dt>
<dd>the seed used to initialize the environment</dd>
</dl>
<p>and each environment will have its own seed]. Defaults to True.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class NoAutoResetGymAgent(GymAgent):
    &#34;&#34;&#34;The same as GymAgent, named to make sure it is not AutoReset&#34;&#34;&#34;

    def __init__(
        self,
        make_env_fn=None,
        make_env_args={},
        n_envs=None,
        seed=None,
        action_string=&#34;action&#34;,
        output=&#34;env/&#34;,
    ):
        super().__init__(
            make_env_fn=make_env_fn,
            make_env_args=make_env_args,
            n_envs=n_envs,
            seed=seed,
            action_string=action_string,
            output=output,
        )</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="bbrl.agents.gyma.GymAgent" href="#bbrl.agents.gyma.GymAgent">GymAgent</a></li>
<li><a title="bbrl.agents.agent.Agent" href="agent.html#bbrl.agents.agent.Agent">Agent</a></li>
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="bbrl.agents.gyma.NoAutoResetGymAgent.dump_patches"><code class="name">var <span class="ident">dump_patches</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="bbrl.agents.gyma.NoAutoResetGymAgent.training"><code class="name">var <span class="ident">training</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="bbrl.agents.gyma.GymAgent" href="#bbrl.agents.gyma.GymAgent">GymAgent</a></b></code>:
<ul class="hlist">
<li><code><a title="bbrl.agents.gyma.GymAgent.clone" href="agent.html#bbrl.agents.agent.Agent.clone">clone</a></code></li>
<li><code><a title="bbrl.agents.gyma.GymAgent.forward" href="#bbrl.agents.gyma.GymAgent.forward">forward</a></code></li>
<li><code><a title="bbrl.agents.gyma.GymAgent.get" href="agent.html#bbrl.agents.agent.Agent.get">get</a></code></li>
<li><code><a title="bbrl.agents.gyma.GymAgent.get_by_name" href="agent.html#bbrl.agents.agent.Agent.get_by_name">get_by_name</a></code></li>
<li><code><a title="bbrl.agents.gyma.GymAgent.get_name" href="agent.html#bbrl.agents.agent.Agent.get_name">get_name</a></code></li>
<li><code><a title="bbrl.agents.gyma.GymAgent.get_time_truncated" href="agent.html#bbrl.agents.agent.Agent.get_time_truncated">get_time_truncated</a></code></li>
<li><code><a title="bbrl.agents.gyma.GymAgent.is_running" href="agent.html#bbrl.agents.agent.Agent.is_running">is_running</a></code></li>
<li><code><a title="bbrl.agents.gyma.GymAgent.load_model" href="agent.html#bbrl.agents.agent.Agent.load_model">load_model</a></code></li>
<li><code><a title="bbrl.agents.gyma.GymAgent.save_model" href="agent.html#bbrl.agents.agent.Agent.save_model">save_model</a></code></li>
<li><code><a title="bbrl.agents.gyma.GymAgent.seed" href="agent.html#bbrl.agents.agent.Agent.seed">seed</a></code></li>
<li><code><a title="bbrl.agents.gyma.GymAgent.set" href="agent.html#bbrl.agents.agent.Agent.set">set</a></code></li>
<li><code><a title="bbrl.agents.gyma.GymAgent.set_name" href="agent.html#bbrl.agents.agent.Agent.set_name">set_name</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="bbrl.agents" href="index.html">bbrl.agents</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="bbrl.agents.gyma.AutoResetGymAgent" href="#bbrl.agents.gyma.AutoResetGymAgent">AutoResetGymAgent</a></code></h4>
<ul class="">
<li><code><a title="bbrl.agents.gyma.AutoResetGymAgent.dump_patches" href="#bbrl.agents.gyma.AutoResetGymAgent.dump_patches">dump_patches</a></code></li>
<li><code><a title="bbrl.agents.gyma.AutoResetGymAgent.forward" href="#bbrl.agents.gyma.AutoResetGymAgent.forward">forward</a></code></li>
<li><code><a title="bbrl.agents.gyma.AutoResetGymAgent.training" href="#bbrl.agents.gyma.AutoResetGymAgent.training">training</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="bbrl.agents.gyma.GymAgent" href="#bbrl.agents.gyma.GymAgent">GymAgent</a></code></h4>
<ul class="">
<li><code><a title="bbrl.agents.gyma.GymAgent.dump_patches" href="#bbrl.agents.gyma.GymAgent.dump_patches">dump_patches</a></code></li>
<li><code><a title="bbrl.agents.gyma.GymAgent.forward" href="#bbrl.agents.gyma.GymAgent.forward">forward</a></code></li>
<li><code><a title="bbrl.agents.gyma.GymAgent.get_obs_and_actions_sizes" href="#bbrl.agents.gyma.GymAgent.get_obs_and_actions_sizes">get_obs_and_actions_sizes</a></code></li>
<li><code><a title="bbrl.agents.gyma.GymAgent.is_continuous_action" href="#bbrl.agents.gyma.GymAgent.is_continuous_action">is_continuous_action</a></code></li>
<li><code><a title="bbrl.agents.gyma.GymAgent.is_continuous_state" href="#bbrl.agents.gyma.GymAgent.is_continuous_state">is_continuous_state</a></code></li>
<li><code><a title="bbrl.agents.gyma.GymAgent.is_discrete_action" href="#bbrl.agents.gyma.GymAgent.is_discrete_action">is_discrete_action</a></code></li>
<li><code><a title="bbrl.agents.gyma.GymAgent.is_discrete_state" href="#bbrl.agents.gyma.GymAgent.is_discrete_state">is_discrete_state</a></code></li>
<li><code><a title="bbrl.agents.gyma.GymAgent.set_obs" href="#bbrl.agents.gyma.GymAgent.set_obs">set_obs</a></code></li>
<li><code><a title="bbrl.agents.gyma.GymAgent.training" href="#bbrl.agents.gyma.GymAgent.training">training</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="bbrl.agents.gyma.NoAutoResetGymAgent" href="#bbrl.agents.gyma.NoAutoResetGymAgent">NoAutoResetGymAgent</a></code></h4>
<ul class="">
<li><code><a title="bbrl.agents.gyma.NoAutoResetGymAgent.dump_patches" href="#bbrl.agents.gyma.NoAutoResetGymAgent.dump_patches">dump_patches</a></code></li>
<li><code><a title="bbrl.agents.gyma.NoAutoResetGymAgent.training" href="#bbrl.agents.gyma.NoAutoResetGymAgent.training">training</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>